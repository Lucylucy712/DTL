{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"/work/PCDC/s202005/Research/TransferLearning/Shelburne/Results/summary/\\\n",
    "Single_1_Anti_2_Dense_1024_Ensemble/Epochs_100_Batch_128/Epochs_100_Batch_128_total.csv\"\n",
    "DATA = pd.read_csv(DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(data,epochs_list,batch_list,pred_weights_list,input_weights_list,metric):\n",
    "    if not metric:\n",
    "        return {}\n",
    "    ## get data separately \n",
    "    tempdata = data.copy(deep=True)\n",
    "    if epochs_list:\n",
    "        tempdata = tempdata[tempdata.config_epochs.isin(epochs_list)]\n",
    "    if batch_list:\n",
    "        tempdata = tempdata[tempdata.config_batch.isin(batch_list)]\n",
    "    ## 2. get parp data\n",
    "    ### stratgey: For the same seed + cv, the PARP should be the same \n",
    "    temp_parp = tempdata[(tempdata.model==\"PARP\")]\n",
    "    temp_cols = [ele for ele in temp_parp.columns if \"config\" not in ele] + [\"config_epochs\",\"config_batch\"]\n",
    "    temp_parp = temp_parp[temp_cols]\n",
    "    temp_parp.drop_duplicates(inplace=True)\n",
    "    temp_parp[\"config_method\"] = \"PARP\"\n",
    "    #temp_parp[\"config\"] = temp_parp.apply(lambda x:\"Epochs_\"+str(x[\"config_epochs\"])+\"_Batch_\"+str(x[\"config_batch\"])+\"_PARP\",axis=1)\n",
    "    def parp_config(epochs,batch):\n",
    "        return \"Model: PARP <br>\" + \"Epochs: \"+str(epochs)+\"<br>Batch: \"+str(batch)\n",
    "    temp_parp[\"config\"] = temp_parp.apply(lambda x: parp_config(x[\"config_epochs\"],x[\"config_batch\"]),axis=1)\n",
    "        \n",
    "\n",
    "    ## 3. get DTL data \n",
    "    temp_DTL = tempdata[tempdata.model==\"DTL\"]\n",
    "    if pred_weights_list:\n",
    "        temp_DTL = temp_DTL[temp_DTL.config_pred_weights.isin(pred_weights_list)]\n",
    "    if input_weights_list:\n",
    "        temp_DTL = temp_DTL[temp_DTL.config_input_weights.isin(input_weights_list)]\n",
    "    def dtl_config(epochs,batch,pred_weights,input_weights):\n",
    "        return \"Model: DTL <br>\" + \"Epochs: \"+str(epochs)+\"<br>Batch: \"+str(batch)+\"<br>Pred_weights: \"+pred_weights + \"<br>Input_weights: \"+input_weights\n",
    "    temp_DTL[\"config\"]=temp_DTL.apply(lambda x: dtl_config(x[\"config_epochs\"],x[\"config_batch\"],x[\"config_pred_weights\"],x[\"config_input_weights\"]),axis=1) \n",
    "\n",
    "\n",
    "    ## 4. get TL data \n",
    "    temp_TL = tempdata[tempdata.model==\"TL\"]\n",
    "    if pred_weights_list:\n",
    "        temp_TL = temp_TL[temp_TL.config_pred_weights.isin(pred_weights_list)]\n",
    "    def tl_config(epochs,batch,pred_weights):\n",
    "        return \"Model: TL <br>\" + \"Epochs: \"+str(epochs)+\"<br>Batch: \"+str(batch)+\"<br>Pred_weights: \"+pred_weights\n",
    "    temp_TL[\"config\"]=temp_TL.apply(lambda x: tl_config(x[\"config_epochs\"],x[\"config_batch\"],x[\"config_pred_weights\"]),axis=1) \n",
    "    ## 5. get Scratch data \n",
    "    temp_Scratch = tempdata[tempdata.model==\"Scratch\"]\n",
    "    def scratch_config(epochs,batch):\n",
    "        return \"Model: Scratch <br>\" + \"Epochs: \"+str(epochs)+\"<br>Batch: \"+str(batch)\n",
    "    temp_Scratch[\"config\"] = temp_Scratch.apply(lambda x: scratch_config(x[\"config_epochs\"],x[\"config_batch\"]),axis=1)\n",
    "\n",
    "    ## final data \n",
    "    results = pd.concat([temp_parp,temp_TL,temp_DTL,temp_Scratch])\n",
    "    ## for px\n",
    "    agg_func = {metric:[\"describe\"]}\n",
    "    temp_df = results.groupby([\"config\",\"model\"]).agg(agg_func).reset_index()\n",
    "\n",
    "    temp_df = temp_df.T.reset_index()\n",
    "    temp_df.drop(columns=[\"level_0\",'level_1'],inplace=True)\n",
    "    temp_df.loc[0,\"level_2\"] = \"config\"\n",
    "    temp_df.loc[1,\"level_2\"] = \"model\"\n",
    "    temp_df = temp_df.T\n",
    "    temp_df.columns = temp_df.iloc[0]\n",
    "    temp_df.drop(temp_df.index[0],inplace=True)\n",
    "\n",
    "    total_results = pd.merge(results,temp_df,how=\"left\")\n",
    "    total_results[\"input_w\"] = total_results[\"config_input_weights\"]\n",
    "    total_results[\"pred_w\"] = total_results[\"config_pred_weights\"]\n",
    "    total_results[\"epochs\"] = total_results[\"config_epochs\"]\n",
    "    total_results[\"batch\"] = total_results[\"config_batch\"]\n",
    "    \n",
    "    total_results.sort_values([\"model\",\"input_w\",\"pred_w\",\"batch\",\"epochs\"],inplace=True)\n",
    "    return total_results \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obs 1: robust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"accuracy_score\"\n",
    "overall_best = []\n",
    "for metric in ['f1score','precision_score','accuracy_score',\n",
    "               'balanced_accuracy_score','recall_score','roc_auc_score']:\n",
    "    for batch in list(DATA.config_batch.unique()):\n",
    "        for epochs in list(DATA.config_epochs.unique()):\n",
    "            batch_list = [batch]\n",
    "            epochs_list = [epochs]\n",
    "            pred_weights_list = None \n",
    "            input_weights_list = None \n",
    "            tempresults = get_results(DATA,epochs_list,batch_list,pred_weights_list,input_weights_list,metric)\n",
    "            cols = [\"model\",\"mean\",\"std\",\"input_w\",\"pred_w\",\"epochs\",\"batch\",\"method\"]\n",
    "            tempresults = tempresults[cols]\n",
    "            tempresults.drop_duplicates(inplace=True)\n",
    "\n",
    "            temp_parp = tempresults[tempresults.model==\"PARP\"]\n",
    "            temp_parp = temp_parp.iloc[[0],:]\n",
    "            temp_others = tempresults[tempresults.model!=\"PARP\"]\n",
    "\n",
    "            temp_all = pd.concat([temp_parp,temp_others],axis=0)\n",
    "            temp_all.sort_values([\"mean\",\"std\"],ascending=[True,False],inplace=True)\n",
    "            temp_all.index = range(len(temp_all))\n",
    "            temp_all[\"metric\"] = metric\n",
    "            temp_best = temp_all.loc[[len(temp_all)-1],:]\n",
    "            overall_best.append(temp_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_all = pd.concat(overall_best)\n",
    "# save_path = \"/work/PCDC/s202005/Research/TransferLearning/Shelburne/Results/summary/\\\n",
    "# Single_1_Anti_2_Dense_1024_Ensemble/Epochs_100_Batch_128/best_\"\n",
    "# best_all.to_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>input_w</th>\n",
       "      <th>pred_w</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch</th>\n",
       "      <th>method</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PARP</td>\n",
       "      <td>0.753227</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>DTL</td>\n",
       "      <td>recall_score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model      mean       std input_w pred_w  epochs  batch method        metric\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      10     16    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      20     16    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      50     16    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN     100     16    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      10     32    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      20     32    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      50     32    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN     100     32    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      10     64    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      20     64    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      50     64    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN     100     64    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      10    128    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      20    128    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN      50    128    DTL  recall_score\n",
       "7  PARP  0.753227  0.062813     NaN    NaN     100    128    DTL  recall_score"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = 'recall_score'\n",
    "for batch in list(DATA.config_batch.unique()):\n",
    "    for epochs in list(DATA.config_epochs.unique()):\n",
    "        batch_list = [batch]\n",
    "        epochs_list = [epochs]\n",
    "        pred_weights_list = None \n",
    "        input_weights_list = None \n",
    "        tempresults = get_results(DATA,epochs_list,batch_list,pred_weights_list,input_weights_list,metric)\n",
    "        cols = [\"model\",\"mean\",\"std\",\"input_w\",\"pred_w\",\"epochs\",\"batch\",\"method\"]\n",
    "        tempresults = tempresults[cols]\n",
    "        tempresults.drop_duplicates(inplace=True)\n",
    "\n",
    "        temp_parp = tempresults[tempresults.model==\"PARP\"]\n",
    "        temp_parp = temp_parp.iloc[[0],:]\n",
    "        temp_others = tempresults[tempresults.model!=\"PARP\"]\n",
    "\n",
    "        temp_all = pd.concat([temp_parp,temp_others],axis=0)\n",
    "        temp_all.sort_values([\"mean\",\"std\"],ascending=[True,False],inplace=True)\n",
    "        temp_all.index = range(len(temp_all))\n",
    "        temp_all[\"metric\"] = metric\n",
    "        temp_best = temp_all.loc[[len(temp_all)-1],:]\n",
    "        overall_best.append(temp_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
